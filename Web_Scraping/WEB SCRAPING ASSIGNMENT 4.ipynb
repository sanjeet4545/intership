{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c9f837f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementNotInteractableException\n",
    "\n",
    "import requests\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5938ca29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99277c3a",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "\n",
    "* A) Rank\n",
    "* B) Name\n",
    "* C) Artist\n",
    "* D) Upload date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60410d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Shree Hanuman Chalisa</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                                  Bath Song   \n",
       "4    5.                               Shape of You   \n",
       "5    6.                              See You Again   \n",
       "6    7.                          Wheels on the Bus   \n",
       "7    8.                Phonics Song with Two Words   \n",
       "8    9.                                Uptown Funk   \n",
       "9   10.  Learning Colors – Colorful Eggs on a Farm   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.   Masha and the Bear – Recipe for Disaster   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                     Axel F   \n",
       "14  15.                                      Sugar   \n",
       "15  16.                             Counting Stars   \n",
       "16  17.                                       Roar   \n",
       "17  18.                        Baa Baa Black Sheep   \n",
       "18  19.           Waka Waka (This Time for Africa)   \n",
       "19  20.                                      Sorry   \n",
       "20  21.                             Lakdi Ki Kathi   \n",
       "21  22.                          Thinking Out Loud   \n",
       "22  23.                                 Dark Horse   \n",
       "23  24.          Humpty the train on a fruits ride   \n",
       "24  25.                                    Perfect   \n",
       "25  26.                                 Let Her Go   \n",
       "26  27.                                      Faded   \n",
       "27  28.                             Girls Like You   \n",
       "28  29.                      Shree Hanuman Chalisa   \n",
       "29  30.                                    Lean On   \n",
       "\n",
       "                                               Artist        Upload date  \n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  \n",
       "1                                          Luis Fonsi   January 12, 2017  \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016  \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018  \n",
       "4                                          Ed Sheeran   January 30, 2017  \n",
       "5                                         Wiz Khalifa      April 6, 2015  \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018  \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014  \n",
       "8                                         Mark Ronson  November 19, 2014  \n",
       "9                                         Miroshka TV  February 27, 2018  \n",
       "10                                        officialpsy      July 15, 2012  \n",
       "11                                         Get Movies   January 31, 2012  \n",
       "12                                      Ultra Records      April 5, 2018  \n",
       "13                                         Crazy Frog      June 16, 2009  \n",
       "14                                           Maroon 5   January 14, 2015  \n",
       "15                                        OneRepublic       May 31, 2013  \n",
       "16                                         Katy Perry  September 5, 2013  \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018  \n",
       "18                                            Shakira       June 4, 2010  \n",
       "19                                      Justin Bieber   October 22, 2015  \n",
       "20                                       Jingle Toons      June 14, 2018  \n",
       "21                                         Ed Sheeran    October 7, 2014  \n",
       "22                                         Katy Perry  February 20, 2014  \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018  \n",
       "24                                         Ed Sheeran   November 9, 2017  \n",
       "25                                          Passenger      July 25, 2012  \n",
       "26                                        Alan Walker   December 3, 2015  \n",
       "27                                           Maroon 5       May 31, 2018  \n",
       "28                              T-Series Bhakti Sagar       May 10, 2011  \n",
       "29                               Major Lazer Official     March 22, 2015  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Open the url\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "time.sleep(3)\n",
    "\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]\n",
    "\n",
    "# RAnk \n",
    "rank_tag = driver.find_elements(By.XPATH,'//td[@align=\"center\"][1]')\n",
    "try:\n",
    "    for i in rank_tag[0:30]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append('-')\n",
    "except ElementNotVisibleException:\n",
    "    rank.append(\"--\")\n",
    "            \n",
    "# Name\n",
    "name_tag = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for i in name_tag[0:30]:\n",
    "        v_name=i.text.split('[')\n",
    "        name.append(v_name[0].replace('\"',''))\n",
    "except NoSuchElementException:\n",
    "    name.append(\"-\")\n",
    "except ElementNotVisibleException:\n",
    "    name.append(\"--\")\n",
    "    \n",
    "artist_tag = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for i in artist_tag[0:30]:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    artist.append(\"-\")\n",
    "    \n",
    "date_tag = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "try:\n",
    "    for i in date_tag[0:30]:\n",
    "        upload_date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    upload_date.append(i.text)\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "most_viewed = pd.DataFrame({'Rank':rank,'Name':name,'Artist':artist,'Upload date':upload_date})\n",
    "most_viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1971060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2001132c",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "* A) Series\n",
    "* B) Place\n",
    "* C) Date\n",
    "* D) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dce997",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'/html[1]/body[1]/div[2]/div[2]/div[1]/div[1]/div[1]/div[2]/div[3]/div[2]/div[1]/button[1]').click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"NoSuchElementException \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbc7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium, ...</td>\n",
       "      <td>22 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...</td>\n",
       "      <td>29 OCTOBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>2 NOVEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Eden Gardens, Kolkata</td>\n",
       "      <td>5 NOVEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>12 NOVEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>6 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>4 SEPTEMBER, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NEW ZEALAND A TOUR OF INDIA</td>\n",
       "      <td>M.Chinnaswamy Stadium, Bangalore</td>\n",
       "      <td>1 SEPTEMBER, 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>31 AUGUST, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>Dubai International Cricket Stadium, Dubai</td>\n",
       "      <td>28 AUGUST, 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Series  \\\n",
       "0        ICC MENS WORLD CUP 2023   \n",
       "1        ICC MENS WORLD CUP 2023   \n",
       "2        ICC MENS WORLD CUP 2023   \n",
       "3        ICC MENS WORLD CUP 2023   \n",
       "4        ICC MENS WORLD CUP 2023   \n",
       "..                           ...   \n",
       "206                ASIA CUP 2022   \n",
       "207                ASIA CUP 2022   \n",
       "208  NEW ZEALAND A TOUR OF INDIA   \n",
       "209                ASIA CUP 2022   \n",
       "210                ASIA CUP 2022   \n",
       "\n",
       "                                                 Place               Date  \\\n",
       "0    Himachal Pradesh Cricket Association Stadium, ...   22 OCTOBER, 2023   \n",
       "1    Bharat Ratna Shri Atal Bihari Vajpayee Ekana C...   29 OCTOBER, 2023   \n",
       "2                             Wankhede Stadium, Mumbai   2 NOVEMBER, 2023   \n",
       "3                                Eden Gardens, Kolkata   5 NOVEMBER, 2023   \n",
       "4                     M Chinnaswamy Stadium, Bengaluru  12 NOVEMBER, 2023   \n",
       "..                                                 ...                ...   \n",
       "206         Dubai International Cricket Stadium, Dubai  6 SEPTEMBER, 2022   \n",
       "207         Dubai International Cricket Stadium, Dubai  4 SEPTEMBER, 2022   \n",
       "208                   M.Chinnaswamy Stadium, Bangalore  1 SEPTEMBER, 2022   \n",
       "209         Dubai International Cricket Stadium, Dubai    31 AUGUST, 2022   \n",
       "210         Dubai International Cricket Stadium, Dubai    28 AUGUST, 2022   \n",
       "\n",
       "            Time  \n",
       "0    2:00 PM IST  \n",
       "1    2:00 PM IST  \n",
       "2    2:00 PM IST  \n",
       "3    2:00 PM IST  \n",
       "4    2:00 PM IST  \n",
       "..           ...  \n",
       "206  7:30 PM IST  \n",
       "207  7:30 PM IST  \n",
       "208  9:30 AM IST  \n",
       "209  7:30 PM IST  \n",
       "210  7:30 PM IST  \n",
       "\n",
       "[211 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Open the url\n",
    "driver.get('https://www.bcci.tv/')\n",
    "\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "m_time=[]\n",
    "\n",
    "# Close add tabs\n",
    "driver.find_element(By.XPATH,'//button[@class=\"close-button page-close\"]').click()\n",
    "\n",
    "# Click on the International navigation\n",
    "driver.find_element(By.XPATH,'//div[@id=\"imw-international-men\"]/a[2]').click()\n",
    "\n",
    "time.sleep(5)\n",
    "for _ in range(10):\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'/html[1]/body[1]/div[2]/div[2]/div[1]/div[1]/div[1]/div[2]/div[3]/div[2]/div[1]/button[1]').click()\n",
    "    except NoSuchElementException:\n",
    "        print('-')\n",
    "\n",
    "# Series\n",
    "series_tag = driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "try:\n",
    "    for i in series_tag:\n",
    "        series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    series.append('NA')\n",
    "\n",
    "# Place\n",
    "place_tag = driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')\n",
    "try:\n",
    "    for i in place_tag:\n",
    "        place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    place.append('NA')\n",
    "\n",
    "# Date\n",
    "date_tag = driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "try:\n",
    "    for i in date_tag:\n",
    "        date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    date.append('NA')\n",
    "    \n",
    "# Time\n",
    "time_tag = driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "try:\n",
    "    for i in time_tag:\n",
    "        m_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    m_time.append('NA')\n",
    "    \n",
    "international_fixtures = pd.DataFrame({'Series':series,'Place':place,'Date':date,'Time':m_time})\n",
    "international_fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8009309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a3ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc91b9b1",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "    \n",
    "You have to find following details: \n",
    "* A) Rank\n",
    "* B) State\n",
    "* C) GSDP(18-19)- at current prices\n",
    "* D) GSDP(19-20)- at current prices\n",
    "* E) Share(18-19)\n",
    "* F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce091ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP 19-20</th>\n",
       "      <th>GSDP 18-19</th>\n",
       "      <th>Share 18-19</th>\n",
       "      <th>GDP billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP 19-20 GSDP 18-19 Share 18-19  \\\n",
       "0     1                Maharashtra          -  2,632,792      13.94%   \n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208       8.63%   \n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764       8.39%   \n",
       "3     4                    Gujarat          -  1,502,899       7.96%   \n",
       "4     5                  Karnataka  1,631,977  1,493,127       7.91%   \n",
       "5     6                West Bengal  1,253,832  1,089,898       5.77%   \n",
       "6     7                  Rajasthan  1,020,989    942,586       4.99%   \n",
       "7     8             Andhra Pradesh    972,782    862,957       4.57%   \n",
       "8     9                  Telangana    969,604    861,031       4.56%   \n",
       "9    10             Madhya Pradesh    906,672    809,592       4.29%   \n",
       "10   11                     Kerala          -    781,653       4.14%   \n",
       "11   12                      Delhi    856,112    774,870       4.10%   \n",
       "12   13                    Haryana    831,610    734,163       3.89%   \n",
       "13   14                      Bihar    611,804    530,363       2.81%   \n",
       "14   15                     Punjab    574,760    526,376       2.79%   \n",
       "15   16                     Odisha    521,275    487,805       2.58%   \n",
       "16   17                      Assam          -    315,881       1.67%   \n",
       "17   18               Chhattisgarh    329,180    304,063       1.61%   \n",
       "18   19                  Jharkhand    328,598    297,204       1.57%   \n",
       "19   20                Uttarakhand          -    245,895       1.30%   \n",
       "20   21            Jammu & Kashmir          -    155,956       0.83%   \n",
       "21   22           Himachal Pradesh    165,472    153,845       0.81%   \n",
       "22   23                        Goa     80,449     73,170       0.39%   \n",
       "23   24                    Tripura     55,984     49,845       0.26%   \n",
       "24   25                 Chandigarh          -     42,114       0.22%   \n",
       "25   26                 Puducherry     38,253     34,433       0.18%   \n",
       "26   27                  Meghalaya     36,572     33,481       0.18%   \n",
       "27   28                     Sikkim     32,496     28,723       0.15%   \n",
       "28   29                    Manipur     31,790     27,870       0.15%   \n",
       "29   30                   Nagaland          -     27,283       0.14%   \n",
       "30   31          Arunachal Pradesh          -     24,603       0.13%   \n",
       "31   32                    Mizoram     26,503     22,287       0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -           -   \n",
       "\n",
       "   GDP billion  \n",
       "0      399.921  \n",
       "1      247.629  \n",
       "2      240.726  \n",
       "3      228.290  \n",
       "4      226.806  \n",
       "5      165.556  \n",
       "6      143.179  \n",
       "7      131.083  \n",
       "8      130.791  \n",
       "9      122.977  \n",
       "10     118.733  \n",
       "11     117.703  \n",
       "12     111.519  \n",
       "13      80.562  \n",
       "14      79.957  \n",
       "15      74.098  \n",
       "16      47.982  \n",
       "17      46.187  \n",
       "18      45.145  \n",
       "19      37.351  \n",
       "20      23.690  \n",
       "21      23.369  \n",
       "22      11.115  \n",
       "23       7.571  \n",
       "24       6.397  \n",
       "25       5.230  \n",
       "26       5.086  \n",
       "27       4.363  \n",
       "28       4.233  \n",
       "29       4.144  \n",
       "30       3.737  \n",
       "31       3.385  \n",
       "32           -  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Open the url\n",
    "driver.get('https://statisticstimes.com/')\n",
    "\n",
    "time.sleep(3)\n",
    "economy = driver.find_element(By.XPATH,'//div[@id=\"top\"]/div[2]/div[2]/button')\n",
    "\n",
    "try:\n",
    "    economy.click()\n",
    "    driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]').click()\n",
    "except NoSuchElementException:\n",
    "    driver.get(economy.get_attribute('href'))\n",
    "    \n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    ads=driver.find_element(By.XPATH,'//span[@class=\"ns-8gvvt-e-21\"]')\n",
    "    ads.click()\n",
    "    gdp = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\").click()\n",
    "except NoSuchElementException:\n",
    "    driver.get('https://www.statisticstimes.com/economy/india/indian-states-gdp.php')\n",
    "    \n",
    "time.sleep(3)\n",
    "\n",
    "rank=[]\n",
    "state=[]\n",
    "GSDP_19_20=[]\n",
    "GSDP_18_19=[]\n",
    "share_18_19=[]\n",
    "GDP_billion=[]\n",
    "\n",
    "\n",
    "state_rank=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for i in state_rank:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append('NA')\n",
    "    \n",
    "state_name=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for i in state_name:\n",
    "        state.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    state.append('NA')\n",
    "        \n",
    "GSDP_19_20_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for i in GSDP_19_20_tag:\n",
    "        GSDP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_19_20.append('NA')\n",
    "    \n",
    "GSDP_18_19_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for i in GSDP_18_19_tag:\n",
    "        GSDP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_18_19.append('NA')\n",
    "    \n",
    "share_18_19_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "try:\n",
    "    for i in share_18_19_tag:\n",
    "        share_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    share_18_19.append('NA')\n",
    "    \n",
    "GDP_billion_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "try:\n",
    "    for i in GDP_billion_tag:\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append('NA')\n",
    "    \n",
    "    \n",
    "driver.close()\n",
    "\n",
    "StateWise_GDP=pd.DataFrame({'Rank':rank,'State':state,'GSDP 19-20':GSDP_19_20,'GSDP 18-19':GSDP_18_19,'Share 18-19':share_18_19,'GDP billion':GDP_billion})\n",
    "StateWise_GDP   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd3c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898cb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afaa1ee5",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "    \n",
    "You have to find the following details:\n",
    "    \n",
    "* A) Repository title\n",
    "* B) Repository description\n",
    "* C) Contributors count\n",
    "* D) Language used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94891044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087196e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a3225c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA / TensorRT-LLM</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>[C++, Python, Cuda, CMake, Smarty, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>localsend / localsend</td>\n",
       "      <td></td>\n",
       "      <td>68</td>\n",
       "      <td>[Dart, C++, CMake, Swift, PowerShell, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenBMB / XAgent</td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>[TypeScript, Python, Vue, CSS, Dockerfile, Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WisdomShell / codeshell</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WisdomShell / codeshell-vscode</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>[TypeScript, CSS, JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neuralmagic / deepsparse</td>\n",
       "      <td></td>\n",
       "      <td>41</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Planetary-Computers / autotab-starter</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>[Python, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ByteByteGoHq / system-design-101</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cloudcommunity / Free-Certifications</td>\n",
       "      <td></td>\n",
       "      <td>57</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>danieldonda / Cybersecurity101</td>\n",
       "      <td></td>\n",
       "      <td>NA</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>imartinez / privateGPT</td>\n",
       "      <td></td>\n",
       "      <td>34</td>\n",
       "      <td>[Python, Makefile, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>radius-project / radius</td>\n",
       "      <td></td>\n",
       "      <td>36</td>\n",
       "      <td>[Go, TypeScript, Bicep, Makefile, Shell, Power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ionic-team / ionic-framework</td>\n",
       "      <td></td>\n",
       "      <td>468</td>\n",
       "      <td>[TypeScript, HTML, SCSS, JavaScript, Vue, CSS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>slowmist / SlowMist-Learning-Roadmap-for-Becom...</td>\n",
       "      <td></td>\n",
       "      <td>NA</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e2b-dev / awesome-ai-agents</td>\n",
       "      <td></td>\n",
       "      <td>36</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>felipemotarocha / fullstackweek-store</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>[TypeScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AntonOsika / gpt-engineer</td>\n",
       "      <td></td>\n",
       "      <td>80</td>\n",
       "      <td>[Python, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>commaai / openpilot</td>\n",
       "      <td></td>\n",
       "      <td>519</td>\n",
       "      <td>[Python, C++, C, Shell, Cython, HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>apexcharts / apexcharts.js</td>\n",
       "      <td></td>\n",
       "      <td>151</td>\n",
       "      <td>[JavaScript, CSS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TheRealJoelmatic / RemoveAdblockThing</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>thuml / Time-Series-Library</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>[Shell, Python, Jupyter Notebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>danielgross / localpilot</td>\n",
       "      <td>NA</td>\n",
       "      <td>3</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>babysor / MockingBird</td>\n",
       "      <td></td>\n",
       "      <td>37</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cloudflare / workers-sdk</td>\n",
       "      <td></td>\n",
       "      <td>126</td>\n",
       "      <td>[TypeScript, JavaScript, HTML, Mustache, CSS, F#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hashicorp / terraform-provider-aws</td>\n",
       "      <td></td>\n",
       "      <td>2,875</td>\n",
       "      <td>[Go, HCL, Makefile, Shell, Smarty, JavaScript]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title Repository description  \\\n",
       "0                               NVIDIA / TensorRT-LLM                          \n",
       "1                               localsend / localsend                          \n",
       "2                                    OpenBMB / XAgent                          \n",
       "3                             WisdomShell / codeshell                          \n",
       "4                      WisdomShell / codeshell-vscode                          \n",
       "5                            neuralmagic / deepsparse                          \n",
       "6               Planetary-Computers / autotab-starter                          \n",
       "7                    ByteByteGoHq / system-design-101                          \n",
       "8                cloudcommunity / Free-Certifications                          \n",
       "9                      danieldonda / Cybersecurity101                          \n",
       "10                             imartinez / privateGPT                          \n",
       "11                            radius-project / radius                          \n",
       "12                       ionic-team / ionic-framework                          \n",
       "13  slowmist / SlowMist-Learning-Roadmap-for-Becom...                          \n",
       "14                        e2b-dev / awesome-ai-agents                          \n",
       "15              felipemotarocha / fullstackweek-store                     NA   \n",
       "16                          AntonOsika / gpt-engineer                          \n",
       "17                                commaai / openpilot                          \n",
       "18                         apexcharts / apexcharts.js                          \n",
       "19              TheRealJoelmatic / RemoveAdblockThing                          \n",
       "20                        thuml / Time-Series-Library                          \n",
       "21                           danielgross / localpilot                     NA   \n",
       "22                              babysor / MockingBird                          \n",
       "23                           cloudflare / workers-sdk                          \n",
       "24                 hashicorp / terraform-provider-aws                          \n",
       "\n",
       "   Contributors_count                                      Language_used  \n",
       "0                   6          [C++, Python, Cuda, CMake, Smarty, Shell]  \n",
       "1                  68        [Dart, C++, CMake, Swift, PowerShell, HTML]  \n",
       "2                  13  [TypeScript, Python, Vue, CSS, Dockerfile, Jav...  \n",
       "3                   6                                    [Python, Shell]  \n",
       "4                   6                      [TypeScript, CSS, JavaScript]  \n",
       "5                  41                                           [Python]  \n",
       "6                   2                                 [Python, Makefile]  \n",
       "7                   7                                               [NA]  \n",
       "8                  57                                               [NA]  \n",
       "9                  NA                                               [NA]  \n",
       "10                 34                     [Python, Makefile, Dockerfile]  \n",
       "11                 36  [Go, TypeScript, Bicep, Makefile, Shell, Power...  \n",
       "12                468     [TypeScript, HTML, SCSS, JavaScript, Vue, CSS]  \n",
       "13                 NA                                               [NA]  \n",
       "14                 36                                               [NA]  \n",
       "15                 NA                                       [TypeScript]  \n",
       "16                 80                                 [Python, Makefile]  \n",
       "17                519              [Python, C++, C, Shell, Cython, HTML]  \n",
       "18                151                                  [JavaScript, CSS]  \n",
       "19                  8                                       [JavaScript]  \n",
       "20                 10                  [Shell, Python, Jupyter Notebook]  \n",
       "21                  3                                           [Python]  \n",
       "22                 37                                           [Python]  \n",
       "23                126  [TypeScript, JavaScript, HTML, Mustache, CSS, F#]  \n",
       "24              2,875     [Go, HCL, Makefile, Shell, Smarty, JavaScript]  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Open the url\n",
    "driver.get('https://github.com/')\n",
    "\n",
    "# Clicking on Open Source  menu\n",
    "open_source = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]')\n",
    "try:\n",
    "    open_source.click()\n",
    "    time.sleep(3)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(open_source.get_attribute('href'))\n",
    "    \n",
    "# Clicking on Trending under Open Source sub menu\n",
    "trending = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "try:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "        \n",
    "# Creating Empty list for Scraping Data\n",
    "Title = []\n",
    "Description = []\n",
    "Count = []\n",
    "Language = []\n",
    "description = []\n",
    "\n",
    "# Scraping title of repository\n",
    "title_tag = driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "try:\n",
    "    for i in title_tag:\n",
    "        Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Title.append('NA')\n",
    "                \n",
    "# Scraping repositories URL\n",
    "URL= []\n",
    "link=driver.find_elements(By.XPATH,'//a[@class=\"Link\"]')\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))\n",
    "    \n",
    "for i in URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    # Scraping description of Repository\n",
    "    \n",
    "    try:\n",
    "        description_tag = driver.find_element(By.XPATH,'//p[@class=\"f4 mb-3 \"]')\n",
    "        Description.append(description_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('NA')\n",
    "    \n",
    "    # Scraping Contributor count\n",
    "    try:\n",
    "        count=driver.find_element(By.XPATH,\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        Count.append(count.text)\n",
    "    except NoSuchElementException:\n",
    "        Count.append('NA')\n",
    "    \n",
    "    # Scraping Language\n",
    "    L =[]\n",
    "    try:\n",
    "        lang=driver.find_elements(By.XPATH,\"//li[@class='d-inline']//a//span[1]\")\n",
    "        if lang:\n",
    "            for j in lang:\n",
    "                L.append(j.text)\n",
    "        else:\n",
    "            L.append('NA')\n",
    "        Language.append(L)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('NA')\n",
    "        \n",
    "driver.close()\n",
    "        \n",
    "Github=pd.DataFrame({'Repository title':Title,'Repository description':Description,\n",
    "               'Contributors_count':Count,'Language_used':Language})\n",
    "\n",
    "Github       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db423696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0803c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5b68d6",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "    \n",
    "* A) Song name\n",
    "* B) Artist name\n",
    "* C) Last week rank\n",
    "* D) Peak rank\n",
    "* E) Weeks on board\n",
    "\n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09f44ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D</td>\n",
       "      <td>Jung Kook &amp; Jack Harlow</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Long Journey</td>\n",
       "      <td>Rod Wave</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>But I Got A Beer In My Hand</td>\n",
       "      <td>Luke Bryan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>East Side Of Sorrow</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Where She Goes</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Song_Name              Artist_Name Last_week_rank Peak  \\\n",
       "0            Paint The Town Red                 Doja Cat                       \n",
       "1                        Snooze                      SZA                       \n",
       "2                  Cruel Summer             Taylor Swift                       \n",
       "3                      Fast Car               Luke Combs                       \n",
       "4                            3D  Jung Kook & Jack Harlow                       \n",
       "..                          ...                      ...            ...  ...   \n",
       "95                 Long Journey                 Rod Wave                       \n",
       "96  But I Got A Beer In My Hand               Luke Bryan                       \n",
       "97                      Rubicon               Peso Pluma                       \n",
       "98          East Side Of Sorrow               Zach Bryan                       \n",
       "99               Where She Goes                Bad Bunny                       \n",
       "\n",
       "   Weeks_on_chart  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  \n",
       "..            ...  \n",
       "95                 \n",
       "96                 \n",
       "97                 \n",
       "98                 \n",
       "99                 \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Open the url\n",
    "driver.get('https:/www.billboard.com/ ')\n",
    "\n",
    "# Creating Empty List\n",
    "Song =[]\n",
    "Artist =[]\n",
    "Last_Week_rank=[]\n",
    "Peak_rank =[]\n",
    "Weeks =[]\n",
    "\n",
    "# Clicking on hot 100 option\n",
    "hot_100=driver.find_element(By.XPATH,'//ul[@aria-labelledby=\"mega-menu-item-charts\"]/li[2]/a')\n",
    "try:\n",
    "    hot_100.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(hot_100.get_attribute('href'))\n",
    "time.sleep(2)\n",
    "\n",
    "# Scraping Song Name\n",
    "try:\n",
    "    song=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul[1]/li[1]/h3')\n",
    "    for i in song:\n",
    "        Song.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Song.append('NA')\n",
    "    \n",
    "# Scraping Song Artist Name\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul[1]/li[1]/span')\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append('NA')\n",
    "    \n",
    "# Scraping Song last week rank\n",
    "try:\n",
    "    last_rank=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p u-hidden@tablet\"][1]/ul[1]/li[3]/span[1]')\n",
    "    for i in last_rank:\n",
    "        Last_Week_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Last_Week_rank.append('NA')\n",
    "\n",
    "# Scraping Song peak rank\n",
    "try:\n",
    "    peak=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p u-hidden@tablet\"][1]/ul[1]/li[4]/span[1]')\n",
    "    for i in peak:\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Peak_rank.append('NA')\n",
    "\n",
    "# Scraping Song week on board\n",
    "try:\n",
    "    weeks=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p u-hidden@tablet\"][1]/ul[1]/li[5]/span[1]')\n",
    "    for i in weeks:\n",
    "        Weeks.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks.append('-')\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "#creating dataframe\n",
    "Billboard=pd.DataFrame({'Song_Name':Song,\n",
    "                'Artist_Name':Artist,\n",
    "                'Last_week_rank':Last_Week_rank,\n",
    "                'Peak':Peak_rank,\n",
    "                'Weeks_on_chart':Weeks})\n",
    "\n",
    "Billboard  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bbd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d4321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "640d417c",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.\n",
    "\n",
    "* A) Book name\n",
    "* B) Author name\n",
    "* C) Volumes sold\n",
    "* D) Publisher\n",
    "* E) Genre\n",
    "\n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "480c1754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Title       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conncet the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Open the url\n",
    "driver.get(' https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "time.sleep(1)\n",
    "\n",
    "# Creating Empty Lists\n",
    "Book =[]\n",
    "Author =[]\n",
    "Volumes_sold =[]\n",
    "Publisher =[]\n",
    "Genre =[]\n",
    "\n",
    "# Scraping Book name\n",
    "try:\n",
    "    book=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book:\n",
    "        Book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book.append('-NA')\n",
    "\n",
    "# Scraping Book author's \n",
    "try:\n",
    "    author=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author:\n",
    "        Author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author.append('NA')\n",
    "    \n",
    "# Scraping Volumes sold\n",
    "try:\n",
    "    sold=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in sold:\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volumes_sold.append('NA')\n",
    "    \n",
    "# Scraping publisher \n",
    "try:\n",
    "    publisher=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append('NA')\n",
    "    \n",
    "# Scraping Genre \n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "#creating dataframe\n",
    "Top_Books=pd.DataFrame({\"Book Title\":Book,\n",
    "                \"Author Name\":Author,\n",
    "                'Volumes sold':Volumes_sold,\n",
    "                'Publisher':Publisher,\n",
    "                'Genre':Genre})\n",
    "\n",
    "Top_Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd421091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19e35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "272b6fb6",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/ \n",
    "    \n",
    "You haveto find the following details:\n",
    "\n",
    "* A) Name\n",
    "* B) Year span\n",
    "* C) Genre\n",
    "* D) Run time\n",
    "* E) Ratings\n",
    "* F) Votes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1bb16c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,212,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,282,756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,049,964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>308,528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>267,486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>269,413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,212,800  \n",
       "1    51 min     8.7  1,282,756  \n",
       "2    44 min     8.1  1,049,964  \n",
       "3    60 min     7.5    308,528  \n",
       "4    43 min     7.6    267,486  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,944  \n",
       "96   50 min     7.8     65,013  \n",
       "97   42 min     8.1    211,851  \n",
       "98   45 min       7     44,090  \n",
       "99  572 min     8.6    269,413  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Open the url\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "time.sleep(1)\n",
    "\n",
    "# Creating Empty List\n",
    "Name =[]\n",
    "Year_Span=[]\n",
    "Genre =[]\n",
    "Run_Time =[]\n",
    "Ratings =[]\n",
    "Votes =[]\n",
    "\n",
    "# Scraping Name \n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')\n",
    "\n",
    "# Scraping Year span \n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in year:\n",
    "        Year_Span.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year_Span.append('NA')\n",
    "    \n",
    "# Scraping Genre \n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')\n",
    "    \n",
    "# Scraping RunTime \n",
    "try:\n",
    "    runtime=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in runtime:\n",
    "        Run_Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Run_Time.append('NA')\n",
    "\n",
    "# Scraping Ratings \n",
    "try:\n",
    "    ratings=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    for i in ratings:\n",
    "        Ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Ratings.append('NA')\n",
    "\n",
    "# Scraping Votes \n",
    "try:\n",
    "    votes=driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Votes.append('NA')\n",
    "    \n",
    "driver.close()\n",
    "    \n",
    "#creating dataframe\n",
    "IMDB_TV=pd.DataFrame({\"Name\":Name,\n",
    "                \"Year Span\":Year_Span,\n",
    "                \"Genre\":Genre,\n",
    "                \"Run Time\":Run_Time,\n",
    "                \"Ratings\":Ratings,\n",
    "                \"Votes\":Votes})\n",
    "\n",
    "IMDB_TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76efb576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608cfdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2ce2a6",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/ \n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "* A) Dataset name\n",
    "* B) Data type\n",
    "* C) Task\n",
    "* D) Attribute type\n",
    "* E) No of instances\n",
    "* F) No of attribute \n",
    "* G) Year\n",
    " \n",
    "Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3e27c95f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet Title</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          DataSet Title                  Data Type  \\\n",
       "0                                  Iris                    Tabular   \n",
       "1                         Heart Disease               Multivariate   \n",
       "2                                 Adult               Multivariate   \n",
       "3                                  Wine                    Tabular   \n",
       "4  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "5                              Diabetes  Multivariate, Time-Series   \n",
       "6                      Dry Bean Dataset               Multivariate   \n",
       "7                        Car Evaluation               Multivariate   \n",
       "8            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "9                          Wine Quality               Multivariate   \n",
       "\n",
       "                         Task              Attribute Type No of Instances  \\\n",
       "0              Classification                        Real             150   \n",
       "1              Classification  Categorical, Integer, Real             303   \n",
       "2              Classification        Categorical, Integer           48842   \n",
       "3              Classification               Integer, Real             178   \n",
       "4              Classification                        Real             569   \n",
       "5                           -        Categorical, Integer               -   \n",
       "6              Classification               Integer, Real           13611   \n",
       "7              Classification                 Categorical            1728   \n",
       "8              Classification                        Real            3810   \n",
       "9  Classification, Regression                        Real            4898   \n",
       "\n",
       "  No of Attribute  \n",
       "0               4  \n",
       "1              13  \n",
       "2              14  \n",
       "3              13  \n",
       "4              30  \n",
       "5              20  \n",
       "6              16  \n",
       "7               6  \n",
       "8               7  \n",
       "9              11  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Open the url\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "time.sleep(1)\n",
    "\n",
    "# Clicking on all datasets links\n",
    "dataset=driver.find_element(By.XPATH,'//a[@class=\"btn-primary btn\"]')\n",
    "dataset.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# Creating empty lists\n",
    "Dataset =[]\n",
    "Data_Type =[]\n",
    "Task =[]\n",
    "Attribute_Type =[]\n",
    "No_of_Instances =[]\n",
    "No_of_Attribute =[]\n",
    "Year =[]\n",
    "Dataset_URL = []\n",
    "\n",
    "url = driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in url:\n",
    "    Dataset_URL.append(i.get_attribute('href'))\n",
    "    \n",
    "for i in Dataset_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(2) \n",
    "    \n",
    "    # Scraping DataSet Name\n",
    "    try:\n",
    "        dataset=driver.find_elements(By.XPATH,'//h1[@class=\"text-3xl font-semibold text-primary-content\"]')\n",
    "        for i in dataset:\n",
    "            Dataset.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset.append('NA')\n",
    "\n",
    "\n",
    "    # Scraping Data Type\n",
    "    try:\n",
    "        Type=driver.find_elements(By.XPATH,'//div[@class=\"col-span-4\"][1]/p')\n",
    "        for i in Type:\n",
    "            Data_Type.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_Type.append('NA')\n",
    "\n",
    "    # Scraping Task\n",
    "    try:\n",
    "        task=driver.find_elements(By.XPATH,'//div[@class=\"col-span-4\"][3]/p')\n",
    "        for i in task:\n",
    "            Task.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('NA')\n",
    "\n",
    "    # Scraping Attribute_Type \n",
    "    try:\n",
    "        attribute_Type=driver.find_elements(By.XPATH,'//div[@class=\"col-span-4\"][4]/p')\n",
    "        for i in attribute_Type:\n",
    "            Attribute_Type.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_Type.append('NA')\n",
    "\n",
    "    # Scraping No_of_Instances \n",
    "    try:\n",
    "        no_of_Instances=driver.find_elements(By.XPATH,'//div[@class=\"col-span-4\"][5]/p')\n",
    "        for i in no_of_Instances:\n",
    "            No_of_Instances.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_Instances.append('NA')\n",
    "\n",
    "    # Scraping No_of_Attribute\n",
    "    try:\n",
    "        no_of_Attribute=driver.find_elements(By.XPATH,'//div[@class=\"col-span-4\"][6]/p')\n",
    "        for i in no_of_Attribute:\n",
    "            No_of_Attribute.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_Attribute.append('NA')\n",
    "\n",
    "    # Scraping Year\n",
    "    try:\n",
    "        year=driver.find_elements(By.XPATH,'//h2[@class=\"text-sm text-primary-content\"]')\n",
    "        for i in year:\n",
    "            Year.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append('NA')\n",
    "        \n",
    "driver.close()\n",
    "        \n",
    "# Creating Data Frame for UCI Dataset\n",
    "UCI_Dataset=pd.DataFrame({'DataSet Title':Dataset,\n",
    "                'Data Type':Data_Type,\n",
    "                'Task':Task,\n",
    "                'Attribute Type':Attribute_Type,\n",
    "                'No of Instances':No_of_Instances,\n",
    "                'No of Attribute':No_of_Attribute,\n",
    "                })\n",
    "\n",
    "UCI_Dataset    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
