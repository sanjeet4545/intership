{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86f9479",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment1 BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b13431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c97f4af",
   "metadata": {},
   "source": [
    "### Q1 - Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e80b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia Main Page Header Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From today's featured list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wikipedia Main Page Header Tag\n",
       "0                       Main Page\n",
       "1            Welcome to Wikipedia\n",
       "2   From today's featured article\n",
       "3                Did you know ...\n",
       "4                     In the news\n",
       "5                     On this day\n",
       "6      From today's featured list\n",
       "7        Today's featured picture\n",
       "8        Other areas of Wikipedia\n",
       "9     Wikipedia's sister projects\n",
       "10            Wikipedia languages"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')   # Check response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(page.text)                # Getting Page Content\n",
    "\n",
    "wiki_header = []\n",
    "\n",
    "for i in soup.find_all(['h1','h2']):\n",
    "    wiki_header.append(i.text)\n",
    "    \n",
    "WikipediaHeader = pd.DataFrame({})     # Convert into dataframe\n",
    "WikipediaHeader['wikipedia Main Page Header Tag'] = wiki_header\n",
    "\n",
    "WikipediaHeader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b7215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a8454cd",
   "metadata": {},
   "source": [
    "### Q -2 Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d57db9cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Presidents Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Presidents Name\n",
       "0           Shri Ram Nath Kovind\n",
       "1          Shri Pranab Mukherjee\n",
       "2   Smt Pratibha Devisingh Patil\n",
       "3         DR. A.P.J. Abdul Kalam\n",
       "4           Shri K. R. Narayanan\n",
       "5        Dr Shankar Dayal Sharma\n",
       "6            Shri R Venkataraman\n",
       "7               Giani Zail Singh\n",
       "8      Shri Neelam Sanjiva Reddy\n",
       "9       Dr. Fakhruddin Ali Ahmed\n",
       "10  Shri Varahagiri Venkata Giri\n",
       "11              Dr. Zakir Husain\n",
       "12  Dr. Sarvepalli Radhakrishnan\n",
       "13           Dr. Rajendra Prasad"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://presidentofindia.nic.in/former-presidents')   # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(page.text)                                   # Getting page Content\n",
    "\n",
    "presidents_name = []\n",
    "\n",
    "for i in soup.find_all('h3'):\n",
    "    presidents_name.append(i.text)\n",
    "\n",
    "# Convert into dataframe\n",
    "df = pd.DataFrame({'Presidents Name':presidents_name})\n",
    " \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91b59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46339aab",
   "metadata": {},
   "source": [
    "### Q - 3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1e82ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>26</td>\n",
       "      <td>3,061</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>39</td>\n",
       "      <td>4,516</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>3,102</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>2,790</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>30</td>\n",
       "      <td>3,057</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>22</td>\n",
       "      <td>2,218</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>37</td>\n",
       "      <td>3,448</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>32</td>\n",
       "      <td>2,941</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>21</td>\n",
       "      <td>1,687</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,582</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches Points Ratings\n",
       "0     Australia      26  3,061     118\n",
       "1         India      39  4,516     116\n",
       "2      Pakistan      27  3,102     115\n",
       "3       England      27  2,790     103\n",
       "4   New Zealand      30  3,057     102\n",
       "5  South Africa      22  2,218     101\n",
       "6     Sri Lanka      37  3,448      93\n",
       "7    Bangladesh      32  2,941      92\n",
       "8   Afghanistan      21  1,687      80\n",
       "9   West Indies      38  2,582      68"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')        # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(page.content)                                               # Getting page Content\n",
    "\n",
    "Country = []\n",
    "Matches = []\n",
    "Points = []\n",
    "Rating = []\n",
    "\n",
    "# Country\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    Country.append(i.text)\n",
    "    Country = Country[:10]\n",
    "\n",
    "# Matches\n",
    "for i in soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    Matches.append(i.text)\n",
    "\n",
    "# Points\n",
    "for i in soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    Points.append(i.text)\n",
    "\n",
    "# Rating\n",
    "for i in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    Rating.append(i.text.replace('\\n',\"\").replace('                            ',\"\"))\n",
    "    \n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    Rating.append(i.text)\n",
    "    Rating = Rating[:10]\n",
    "    \n",
    "center = []\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    center.append(i.text)\n",
    "\n",
    "for i in range(0,len(center)):\n",
    "    if i==0 or i/2 == i//2:\n",
    "        Matches.append(center[i])\n",
    "    else:\n",
    "        Points.append(center[i])\n",
    "\n",
    "Matches = Matches[:10]\n",
    "Points = Points[:10]\n",
    "\n",
    "# Convert into dataframe\n",
    "df = pd.DataFrame({'Country':Country,'Matches':Matches,'Points':Points,'Ratings':Rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63451866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8a8fa1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsman_name</th>\n",
       "      <th>Batsman_nation</th>\n",
       "      <th>Batsman_Rattings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Batsman_name Batsman_nation Batsman_Rattings\n",
       "0             Babar Azam            PAK              863\n",
       "1           Shubman Gill            IND              759\n",
       "2  Rassie van der Dussen             SA              745\n",
       "3           David Warner            AUS              739\n",
       "4            Imam-ul-Haq            PAK              735\n",
       "5           Harry Tector            IRE              726\n",
       "6        Quinton de Kock             SA              721\n",
       "7            Virat Kohli            IND              715\n",
       "8           Rohit Sharma            IND              707\n",
       "9           Fakhar Zaman            PAK              705"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "batsmens = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')      # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(batsmens.text)                                        # Getting page Content\n",
    " \n",
    "Name = []\n",
    "Nation = []\n",
    "Rating = []\n",
    "\n",
    "# Name\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    Name.append(i.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    Name.append(i.text.replace('\\n',''))\n",
    "    Name = Name[:10] \n",
    "\n",
    "# Nation\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    Nation.append(i.text.replace('\\n','').replace('          ',''))\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    Nation.append(i.text)\n",
    "    Nation = Nation[:10]\n",
    "\n",
    "# Rating\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    Rating.append(i.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating.append(i.text)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "# Convert into dataframe    \n",
    "Top_Batsmens = pd.DataFrame({'Batsman_name':Name,'Batsman_nation':Nation,'Batsman_Rattings':Rating})\n",
    "\n",
    "Top_Batsmens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f1bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97e7ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowler_name</th>\n",
       "      <th>Bowler_nation</th>\n",
       "      <th>Bowler_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kuldeep Yadav</td>\n",
       "      <td>IND</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bowler_name Bowler_nation Bowler_rating\n",
       "0    Josh Hazlewood           AUS           692\n",
       "1    Mitchell Starc           AUS           666\n",
       "2       Trent Boult            NZ           666\n",
       "3        Adam Zampa           AUS           663\n",
       "4        Matt Henry            NZ           658\n",
       "5  Mujeeb Ur Rahman           AFG           657\n",
       "6     Kuldeep Yadav           IND           656\n",
       "7       Rashid Khan           AFG           655\n",
       "8    Mohammed Siraj           IND           643\n",
       "9    Shaheen Afridi           PAK           635"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "bowlers = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')       # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(bowlers.text)                                                        # Getting page Content\n",
    " \n",
    "\n",
    "Name = []\n",
    "Nation = []\n",
    "Rating = []\n",
    "\n",
    "# Name\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    Name.append(i.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    Name.append(i.text.replace('\\n',''))\n",
    "    Name = Name[:10]\n",
    "\n",
    "# Nation\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    Nation.append(i.text.replace('\\n','').replace('          ',''))\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    Nation.append(i.text)\n",
    "    Nation = Nation[:10]\n",
    "    \n",
    "# Rating\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    Rating.append(i.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating.append(i.text)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "# Convert into dataframe\n",
    "Top_Bowlers = pd.DataFrame({'Bowler_name':Name,'Bowler_nation':Nation,'Bowler_rating':Rating})\n",
    "Top_Bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef19a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e0feaa7",
   "metadata": {},
   "source": [
    "### Q - 4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2e17f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>26</td>\n",
       "      <td>4,290</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>31</td>\n",
       "      <td>3,875</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>30</td>\n",
       "      <td>3,039</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>28</td>\n",
       "      <td>2,688</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>29</td>\n",
       "      <td>2,743</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>17</td>\n",
       "      <td>1,284</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>12</td>\n",
       "      <td>820</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>13</td>\n",
       "      <td>883</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches Points Rating\n",
       "0     Australia      26  4,290    165\n",
       "1       England      31  3,875    125\n",
       "2  South Africa      26  3,098    119\n",
       "3         India      30  3,039    101\n",
       "4   New Zealand      28  2,688     96\n",
       "5   West Indies      29  2,743     95\n",
       "6    Bangladesh      17  1,284     76\n",
       "7     Sri Lanka      12    820     68\n",
       "8      Thailand      13    883     68\n",
       "9      Pakistan      27  1,678     62"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')         # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(page.text)                                                   # Getting page Content\n",
    "\n",
    "Country = []\n",
    "Matches = []\n",
    "Points = []\n",
    "Rating = []\n",
    "\n",
    "# Country\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    Country.append(i.text)\n",
    "    Country = Country[:10]\n",
    "    \n",
    "# Matches\n",
    "for i in soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    Matches.append(i.text)\n",
    "\n",
    "# Points \n",
    "for i in soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    Points.append(i.text)\n",
    "    \n",
    "# Rating \n",
    "for i in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    Rating.append(i.text.replace('\\n','').replace('              ',''))\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    Rating.append(i.text)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "# Extract elemts \n",
    "Mix = []\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    Mix.append(i.text)\n",
    "\n",
    "for i in range(0,len(Mix)):\n",
    "    if i==0 or i/2 == i//2:\n",
    "        Matches.append(Mix[i])\n",
    "    else:\n",
    "        Points.append(Mix[i])\n",
    "\n",
    "Matches = Matches[:10]        \n",
    "Points  = Points[:10]        \n",
    "        \n",
    "# Convert into dataframe\n",
    "df = pd.DataFrame({'Country':Country,'Matches':Matches,'Points':Points,'Rating':Rating})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0498d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b52470e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_name</th>\n",
       "      <th>Player_nation</th>\n",
       "      <th>Player_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player_name            Player_nation Player_rating\n",
       "0  Natalie Sciver-Brunt  ENG                               801\n",
       "1           Beth Mooney                      AUS           751\n",
       "2   Chamari Athapaththu                       SL           743\n",
       "3       Laura Wolvaardt                       SA           708\n",
       "4       Smriti Mandhana                      IND           708\n",
       "5          Alyssa Healy                      AUS           702\n",
       "6      Harmanpreet Kaur                      IND           694\n",
       "7          Ellyse Perry                      AUS           686\n",
       "8           Meg Lanning                      AUS           682\n",
       "9       Stafanie Taylor                       WI           618"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')        # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(page.text)                                                      # Getting page Content                                                     \n",
    "\n",
    "Name = []\n",
    "Nation = []\n",
    "Rating = []\n",
    "\n",
    "# Name\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    Name.append(i.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    Name.append(i.text.replace('\\n',''))\n",
    "    Name = Name[:10]\n",
    "\n",
    "# Nation\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    Nation.append(i.text.replace('\\n',''))\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    Nation.append(i.text)\n",
    "    Nation = Nation[:10]\n",
    "\n",
    "# Rating\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    Rating.append(i.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating.append(i.text)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "# Convert into dataframe\n",
    "Top_Batsmen = pd.DataFrame({'Player_name':Name,'Player_nation':Nation,'Player_rating':Rating})\n",
    "\n",
    "Top_Batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b0bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecba1405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_name</th>\n",
       "      <th>Player_nation</th>\n",
       "      <th>Player_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>SA</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>AUS</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>ENG</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>SA</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rajeshwari Gayakwad</td>\n",
       "      <td>IND</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player_name Player_nation Player_rating\n",
       "0    Sophie Ecclestone           ENG           761\n",
       "1       Shabnim Ismail            SA           708\n",
       "2        Jess Jonassen           AUS           682\n",
       "3     Ashleigh Gardner           AUS           673\n",
       "4         Megan Schutt           AUS           666\n",
       "5      Hayley Matthews            WI           662\n",
       "6           Kate Cross           ENG           660\n",
       "7       Ayabonga Khaka            SA           646\n",
       "8        Deepti Sharma           IND           607\n",
       "9  Rajeshwari Gayakwad           IND           599"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling')         # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(page.text)                                                           # Getting page Content\n",
    "\n",
    "Name   = []\n",
    "Nation = []\n",
    "Rating = []\n",
    "\n",
    "# Name\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    Name.append(i.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    Name.append(i.text.replace('\\n',''))\n",
    "    Name = Name[:10]\n",
    "\n",
    "# Nation\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    Nation.append(i.text.replace('\\n','').replace('          ',''))\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    Nation.append(i.text)\n",
    "    Nation = Nation[:10]\n",
    "    \n",
    "# Rating\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    Rating.append(i.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating.append(i.text)\n",
    "    Rating = Rating[:10]\n",
    "\n",
    "# Convert into dataframe\n",
    "Top_bowler = pd.DataFrame({'Player_name':Name,'Player_nation':Nation,'Player_rating':Rating})\n",
    "\n",
    "Top_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893d18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e79193c",
   "metadata": {},
   "source": [
    "### Q - 5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame-\n",
    "\n",
    "    i) Headline\n",
    "\n",
    "    ii) Time\n",
    "\n",
    "    iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "831093ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News_Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here's what we think about the big time buyout...</td>\n",
       "      <td>7 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/heres-what-we-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hispanic and Latina women's investing confiden...</td>\n",
       "      <td>16 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/hispanic-and-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Planet Fitness shares sink 15% after board ous...</td>\n",
       "      <td>23 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/planet-fitness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan borrowers at risk of scams as pay...</td>\n",
       "      <td>28 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/student-loan-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This company is transforming the energy drink ...</td>\n",
       "      <td>47 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/this-company-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Here's where AMC and GameStop are now as 'Dumb...</td>\n",
       "      <td>48 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/heres-where-am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The No. 1 'underrated' nutrient you’ve never h...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/underrated-nut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CFP: 'My wife and I have almost entirely separ...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/cfp-how-my-wif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Buy this landfill stock as it flexes its stron...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/buy-this-landf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>529 college savings plans had a major sticking...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/529-college-sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Top 10 things to watch in the stock market Friday</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/top-10-things-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Why Stellantis could face a longer strike than...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/stellantis-cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What to know about the deal between fast-food ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/california-fas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A degree from this Ivy League university can a...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/colleges-that-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stocks making biggest moves premarket: Arm Hol...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Friday's biggest analyst calls: Apple, GM, Ama...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/fridays-top-wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Women are more likely to face these financial ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/women-are-more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sell Rosh Hashanah, buy Yom Kippur? What's beh...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/sell-rosh-hash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Video game developer is poised to ride the inn...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/this-video-gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5 things to know before the stock market opens...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/5-things-to-kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Trump, DeSantis go head-to-head at key conserv...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/trump-desantis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Shipping giant Maersk is seeing tentative sign...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/shipping-giant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Arm valuation already 'looks full' after IPO, ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/arm-valuation-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Yum China says tech let it open stores without...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/yum-china-says...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Covid, RSV and flu shots are here: How to deci...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/covid-rsv-flu-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Here's what analysts are saying after Adobe's ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/heres-what-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oil just hit its highest level of the year — a...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/oil-to-hit-100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TD Cowen: Buy Bud Light owner AB InBev stock a...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/buy-bud-light-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Arm's second trading day is more subdued, but ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/arm-shares-sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Buy the dip on this technology stock for nearl...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/15/buy-the-dip-on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline         Time  \\\n",
       "0   Here's what we think about the big time buyout...    7 Min Ago   \n",
       "1   Hispanic and Latina women's investing confiden...   16 Min Ago   \n",
       "2   Planet Fitness shares sink 15% after board ous...   23 Min Ago   \n",
       "3   Student loan borrowers at risk of scams as pay...   28 Min Ago   \n",
       "4   This company is transforming the energy drink ...   47 Min Ago   \n",
       "5   Here's where AMC and GameStop are now as 'Dumb...   48 Min Ago   \n",
       "6   The No. 1 'underrated' nutrient you’ve never h...   1 Hour Ago   \n",
       "7   CFP: 'My wife and I have almost entirely separ...  2 Hours Ago   \n",
       "8   Buy this landfill stock as it flexes its stron...  2 Hours Ago   \n",
       "9   529 college savings plans had a major sticking...  2 Hours Ago   \n",
       "10  Top 10 things to watch in the stock market Friday  2 Hours Ago   \n",
       "11  Why Stellantis could face a longer strike than...  3 Hours Ago   \n",
       "12  What to know about the deal between fast-food ...  3 Hours Ago   \n",
       "13  A degree from this Ivy League university can a...  3 Hours Ago   \n",
       "14  Stocks making biggest moves premarket: Arm Hol...  3 Hours Ago   \n",
       "15  Friday's biggest analyst calls: Apple, GM, Ama...  3 Hours Ago   \n",
       "16  Women are more likely to face these financial ...  3 Hours Ago   \n",
       "17  Sell Rosh Hashanah, buy Yom Kippur? What's beh...  3 Hours Ago   \n",
       "18  Video game developer is poised to ride the inn...  4 Hours Ago   \n",
       "19  5 things to know before the stock market opens...  4 Hours Ago   \n",
       "20  Trump, DeSantis go head-to-head at key conserv...  4 Hours Ago   \n",
       "21  Shipping giant Maersk is seeing tentative sign...  4 Hours Ago   \n",
       "22  Arm valuation already 'looks full' after IPO, ...  4 Hours Ago   \n",
       "23  Yum China says tech let it open stores without...  4 Hours Ago   \n",
       "24  Covid, RSV and flu shots are here: How to deci...  5 Hours Ago   \n",
       "25  Here's what analysts are saying after Adobe's ...  5 Hours Ago   \n",
       "26  Oil just hit its highest level of the year — a...  5 Hours Ago   \n",
       "27  TD Cowen: Buy Bud Light owner AB InBev stock a...  5 Hours Ago   \n",
       "28  Arm's second trading day is more subdued, but ...  5 Hours Ago   \n",
       "29  Buy the dip on this technology stock for nearl...  6 Hours Ago   \n",
       "\n",
       "                                            News_Line  \n",
       "0   https://www.cnbc.com/2023/09/15/heres-what-we-...  \n",
       "1   https://www.cnbc.com/2023/09/15/hispanic-and-l...  \n",
       "2   https://www.cnbc.com/2023/09/15/planet-fitness...  \n",
       "3   https://www.cnbc.com/2023/09/15/student-loan-b...  \n",
       "4   https://www.cnbc.com/2023/09/15/this-company-i...  \n",
       "5   https://www.cnbc.com/2023/09/15/heres-where-am...  \n",
       "6   https://www.cnbc.com/2023/09/15/underrated-nut...  \n",
       "7   https://www.cnbc.com/2023/09/15/cfp-how-my-wif...  \n",
       "8   https://www.cnbc.com/2023/09/15/buy-this-landf...  \n",
       "9   https://www.cnbc.com/2023/09/15/529-college-sa...  \n",
       "10  https://www.cnbc.com/2023/09/15/top-10-things-...  \n",
       "11  https://www.cnbc.com/2023/09/15/stellantis-cou...  \n",
       "12  https://www.cnbc.com/2023/09/15/california-fas...  \n",
       "13  https://www.cnbc.com/2023/09/15/colleges-that-...  \n",
       "14  https://www.cnbc.com/2023/09/15/stocks-making-...  \n",
       "15  https://www.cnbc.com/2023/09/15/fridays-top-wa...  \n",
       "16  https://www.cnbc.com/2023/09/15/women-are-more...  \n",
       "17  https://www.cnbc.com/2023/09/15/sell-rosh-hash...  \n",
       "18  https://www.cnbc.com/2023/09/15/this-video-gam...  \n",
       "19  https://www.cnbc.com/2023/09/15/5-things-to-kn...  \n",
       "20  https://www.cnbc.com/2023/09/15/trump-desantis...  \n",
       "21  https://www.cnbc.com/2023/09/15/shipping-giant...  \n",
       "22  https://www.cnbc.com/2023/09/15/arm-valuation-...  \n",
       "23  https://www.cnbc.com/2023/09/15/yum-china-says...  \n",
       "24  https://www.cnbc.com/2023/09/15/covid-rsv-flu-...  \n",
       "25  https://www.cnbc.com/2023/09/15/heres-what-ana...  \n",
       "26  https://www.cnbc.com/2023/09/15/oil-to-hit-100...  \n",
       "27  https://www.cnbc.com/2023/09/15/buy-bud-light-...  \n",
       "28  https://www.cnbc.com/2023/09/15/arm-shares-sec...  \n",
       "29  https://www.cnbc.com/2023/09/15/buy-the-dip-on...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.cnbc.com/world/?region=world')                # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(page.text)                                             # Getting page Content\n",
    "\n",
    "Headline = []\n",
    "Time = []\n",
    "News_Link = []\n",
    "\n",
    "# Headline\n",
    "for i in soup('div',class_=\"LatestNews-headlineWrapper\"):\n",
    "    Headline.append(i.text.replace('2023','Ago').split('Ago')[1])\n",
    "\n",
    "# Time\n",
    "for i in soup('time',class_=\"LatestNews-timestamp\"):\n",
    "    Time.append(i.text)\n",
    "\n",
    "# News_link\n",
    "for i in soup('a',class_=\"LatestNews-headline\"):\n",
    "    News_Link.append(i['href'])\n",
    "\n",
    "# Convert into dataframe\n",
    "Latest_news = pd.DataFrame({'Headline':Headline,'Time':Time,'News_Line':News_Link})\n",
    "\n",
    "Latest_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc71bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9596dba0",
   "metadata": {},
   "source": [
    "### Q - 6) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "\n",
    "Scrape below mentioned details and make data frame\n",
    "          \n",
    "        i) Paper Title\n",
    "        ii) Authors\n",
    "        iii) Published Date\n",
    "        iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3d5d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                         Tim Miller    February 2019   \n",
       "2                                  Margaret A. Boden      August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
       "5                     Henry Prakken, Giovanni Sartor     October 2015   \n",
       "6    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
       "7          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "9                      Saurabh Arora, Prashant Doshi      August 2021   \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "16                        Ron Kohavi, George H. John    December 1997   \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "18   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
       "19                            Luigia Carlucci Aiello        June 2016   \n",
       "20            Patrick Lin, Keith Abney, George Bekey       April 2011   \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                                  URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')   # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(page.text)                                                      # Getting page Content\n",
    "\n",
    "Paper_Title    =  []\n",
    "Authors        =  []\n",
    "Published_Date =  []\n",
    "Paper_URL      =  []\n",
    "\n",
    "# Paper_Title\n",
    "for i in soup.find_all('a',class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    Paper_Title.append(i.text)\n",
    "    \n",
    "# Authors\n",
    "for i in soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    Authors.append(i.text)\n",
    "\n",
    "# Published_Data\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    Published_Date.append(i.text)\n",
    "\n",
    "# Paper_URL \n",
    "for i in soup.find_all('a',class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    Paper_URL.append(i.get('href'))\n",
    "\n",
    "# Convert into dataframe\n",
    "AI_Articles = pd.DataFrame({'Title':Paper_Title,'Authors':Authors,'Published Date':Published_Date,'URL':Paper_URL})\n",
    "\n",
    "AI_Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4228e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89955fb2",
   "metadata": {},
   "source": [
    "### Q - 7) Write a python program to scrape mentioned details from dineout.co.inand make data frame\n",
    "\n",
    "     i) Restaurant name\n",
    "     ii) Cuisine\n",
    "     iii) Location\n",
    "     iv) Ratings\n",
    "     v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4aba877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>Rs 2,000 for 2 (approx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Rs 3,000 for 2 (approx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle's BarbequePacific Mall,Tagore Garden, W...</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Rs 2,000 for 2 (approx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Rs 2,400 for 2 (approx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Rs 1,700 for 2 (approx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Rs 1,800 for 2 (approx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Rs 1,900 for 2 (approx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Rs 2,200 for 2 (approx)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Barbeque TimesM2K Corporate Park,Sector 51...</td>\n",
       "      <td>North Indian, Continental, Chinese, South Indian</td>\n",
       "      <td>M2K Corporate Park,Sector 51, Gurgaon</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Rs 1,500 for 2 (approx)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Restaurant name  \\\n",
       "0      Castle BarbequeConnaught Place, Central Delhi   \n",
       "1  Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "2  Castle's BarbequePacific Mall,Tagore Garden, W...   \n",
       "3    India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "4  The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5  Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "6  The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "7  Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "8  The Barbeque TimesM2K Corporate Park,Sector 51...   \n",
       "\n",
       "                                             Cuisine  \\\n",
       "0                              Chinese, North Indian   \n",
       "1                               Italian, Continental   \n",
       "2                              Chinese, North Indian   \n",
       "3                              North Indian, Italian   \n",
       "4                              North Indian, Chinese   \n",
       "5                                       North Indian   \n",
       "6                                       North Indian   \n",
       "7                              North Indian, Mughlai   \n",
       "8   North Indian, Continental, Chinese, South Indian   \n",
       "\n",
       "                                            Location Rating  \\\n",
       "0                     Connaught Place, Central Delhi      4   \n",
       "1  The Leela Ambience Convention Hotel,Shahdara, ...    4.3   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi    3.9   \n",
       "3               Hilton Garden Inn,Saket, South Delhi    3.9   \n",
       "4                 Gardens Galleria,Sector 38A, Noida    3.9   \n",
       "5     Taurus Sarovar Portico,Mahipalpur, South Delhi    3.7   \n",
       "6  Indirapuram Habitat Centre,Indirapuram, Ghaziabad    3.8   \n",
       "7   Suncity Business Tower,Golf Course Road, Gurgaon    4.3   \n",
       "8              M2K Corporate Park,Sector 51, Gurgaon    4.1   \n",
       "\n",
       "                        URL  \n",
       "0  Rs 2,000 for 2 (approx)   \n",
       "1  Rs 3,000 for 2 (approx)   \n",
       "2  Rs 2,000 for 2 (approx)   \n",
       "3  Rs 2,400 for 2 (approx)   \n",
       "4  Rs 1,700 for 2 (approx)   \n",
       "5  Rs 1,800 for 2 (approx)   \n",
       "6  Rs 1,900 for 2 (approx)   \n",
       "7  Rs 2,200 for 2 (approx)   \n",
       "8  Rs 1,500 for 2 (approx)   "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')          # Check Response status\n",
    "\n",
    "print(page,'\\n')\n",
    "\n",
    "soup = BeautifulSoup(page.text)                                              # Getting page Content\n",
    "\n",
    "Restaurant_name =  []\n",
    "Cuisine         =  []\n",
    "Location        =  []\n",
    "Ratings         =  []\n",
    "Image_URL       =  []\n",
    "\n",
    "# Restaurant_name\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    Restaurant_name.append(i.text)\n",
    "    \n",
    "# Cuisine\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    Cuisine.append(i.text.split('|')[1])\n",
    "\n",
    "# Location\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    Location.append(i.text)\n",
    "\n",
    "# Ratings\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "# Image_URL\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    Image_URL.append(i.text.replace('₹','Rs').split('|')[0])\n",
    "\n",
    "# Convert into dataframe\n",
    "Dineout = pd.DataFrame({'Restaurant name':Restaurant_name,'Cuisine':Cuisine,'Location':Location,'Rating':Ratings,'URL':Image_URL})\n",
    "\n",
    "Dineout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
